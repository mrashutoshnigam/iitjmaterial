{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT3KCHHObbmD",
        "outputId": "34b50266-d5c6-486b-d553-1c4dbd8184b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessed successfully!\n",
            "[[-0.4134164  -1.46200287]\n",
            " [ 0.55122187 -0.50256349]\n",
            " [ 0.67180165  0.21701605]\n",
            " [ 0.91296121 -0.02284379]\n",
            " [ 1.63643991  1.41631528]\n",
            " [-0.17225683 -0.26270364]\n",
            " [ 2.11875905 -0.02284379]\n",
            " [-0.29283662 -0.02284379]\n",
            " [-0.89573553  1.17645543]\n",
            " [ 2.23933883 -0.50256349]\n",
            " [-0.05167705 -0.74242333]\n",
            " [-0.77515575  0.93659559]\n",
            " [-1.01631531  1.17645543]\n",
            " [-0.89573553  1.89603497]\n",
            " [-1.01631531 -2.42144225]\n",
            " [ 0.55122187 -0.74242333]\n",
            " [-1.25747488  0.93659559]\n",
            " [-1.01631531 -0.02284379]\n",
            " [-0.89573553  0.69673574]\n",
            " [-0.29283662 -0.74242333]\n",
            " [-0.89573553  0.93659559]\n",
            " [-0.17225683 -0.02284379]\n",
            " [ 2.23933883  1.89603497]\n",
            " [-1.49863445  0.4568759 ]\n",
            " [ 0.43064208 -0.26270364]\n",
            " [-0.17225683 -1.22214302]\n",
            " [-0.4134164   2.85547435]\n",
            " [ 0.18948252 -0.02284379]\n",
            " [-0.05167705 -0.74242333]\n",
            " [ 0.18948252 -1.94172256]\n",
            " [-0.53399618 -0.02284379]\n",
            " [ 0.43064208  0.93659559]\n",
            " [-0.4134164  -1.70186271]\n",
            " [-0.53399618  2.13589481]\n",
            " [-1.01631531 -1.70186271]\n",
            " [ 0.67180165 -0.74242333]\n",
            " [-1.01631531  0.69673574]\n",
            " [-1.01631531  0.4568759 ]\n",
            " [-0.4134164  -1.46200287]\n",
            " [ 1.033541   -0.02284379]\n",
            " [-1.1368951   0.21701605]\n",
            " [-0.05167705 -0.50256349]\n",
            " [-1.01631531  0.93659559]\n",
            " [-1.01631531  1.17645543]\n",
            " [ 0.06890273  0.4568759 ]\n",
            " [-0.89573553 -1.22214302]\n",
            " [ 1.27470056  0.4568759 ]\n",
            " [ 0.18948252 -0.74242333]\n",
            " [ 0.3100623  -0.98228318]\n",
            " [ 2.23933883 -0.02284379]\n",
            " [-0.4134164  -1.22214302]\n",
            " [-1.73979401 -0.26270364]\n",
            " [-1.8603738  -0.02284379]\n",
            " [ 0.18948252 -1.94172256]\n",
            " [ 1.63643991  0.4568759 ]\n",
            " [-1.49863445  0.21701605]\n",
            " [-0.89573553  1.17645543]\n",
            " [-1.73979401 -0.02284379]\n",
            " [ 0.55122187 -1.22214302]\n",
            " [ 0.55122187  0.93659559]\n",
            " [-1.49863445  0.93659559]\n",
            " [ 1.15412078 -0.02284379]\n",
            " [ 0.55122187  0.69673574]\n",
            " [-1.37805466  0.4568759 ]\n",
            " [ 0.3100623  -0.26270364]\n",
            " [ 0.79238143 -0.50256349]\n",
            " [ 0.43064208 -0.50256349]\n",
            " [ 1.39528035  0.4568759 ]\n",
            " [ 0.67180165  0.4568759 ]\n",
            " [-0.89573553  1.89603497]\n",
            " [ 1.27470056  0.21701605]\n",
            " [ 0.06890273 -0.02284379]\n",
            " [ 0.79238143 -0.02284379]\n",
            " [-0.17225683 -0.98228318]\n",
            " [-0.77515575 -0.74242333]\n",
            " [ 0.3100623  -0.02284379]\n",
            " [-1.61921423 -1.70186271]\n",
            " [ 0.91296121 -0.26270364]\n",
            " [-0.4134164  -0.98228318]\n",
            " [-0.65457597  1.65617512]\n",
            " [-0.29283662 -0.02284379]\n",
            " [ 1.7570197  -0.26270364]\n",
            " [ 1.033541    0.69673574]\n",
            " [-0.89573553  1.65617512]\n",
            " [-1.1368951  -1.46200287]\n",
            " [ 1.033541    0.69673574]\n",
            " [ 1.63643991 -0.02284379]\n",
            " [-1.1368951   1.41631528]\n",
            " [ 1.033541    0.21701605]\n",
            " [-1.1368951  -0.02284379]\n",
            " [ 1.27470056  0.21701605]\n",
            " [ 1.87759948 -0.50256349]\n",
            " [ 0.55122187 -0.26270364]\n",
            " [-0.17225683 -0.50256349]\n",
            " [ 0.79238143 -0.02284379]\n",
            " [ 0.55122187 -1.70186271]\n",
            " [ 0.67180165 -0.26270364]\n",
            " [-0.29283662 -0.50256349]\n",
            " [ 0.06890273 -0.02284379]\n",
            " [-0.53399618  0.93659559]\n",
            " [ 0.3100623  -0.50256349]\n",
            " [-1.1368951  -1.22214302]\n",
            " [-0.05167705  2.37575466]\n",
            " [-0.05167705 -0.98228318]\n",
            " [ 1.51586013 -0.02284379]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Load the Iris dataset\n",
        "# The Iris dataset contains 150 samples of 3 classes (Setosa, Versicolour, Virginica) with 4 features each.\n",
        "data = load_iris()\n",
        "X, y = data.data[:, :2], data.target  # Use only the first two features for visualization\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "# 70% of the data is used for training, and 30% is reserved for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 3: Normalize the feature data\n",
        "# StandardScaler standardizes features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit and transform training data\n",
        "X_test = scaler.transform(X_test)  # Transform testing data using the same scaler\n",
        "\n",
        "print(\"Data preprocessed successfully!\")\n",
        "print(X_train)"
      ]
    }
  ]
}